# Infosearch
### Task 1

1. Скачать минимум 100 текстовых страниц с помощью краулера из  предварительно  подготовленного списка

Замечание:
+ список страниц, сайтов можно найти в интернете
+ каждая страница должна содержать текст (ссылки на js, css файлы недопустимы)
+ язык текста  должен быть одинаков для всех страниц

2. Записать каждую страницу в  текстовый файл ("выкачка")

#### Замечание: 
+ очищать выкачку от html разметки  НЕ надо(выкачиваем вместе с разметкой )

3. Создать файл index.txt в котором хранится номер файла и ссылка на страницу

### Task 2
1. Из сохраненных документов выделить отдельные слова (токенизация) и получить список токенов

#### Замечание:
+список не должен содержать дубликатов, союзов, предлогов, чисел
+список не должен  содержать "мусора" (слов содержащих одновременно буквы и цифры, обрывки разметки и тд.)

2. Сгруппировать токены по леммам


### Task 3

1. Создать инвертированный список терминов (индекс)

2. Реализовать булев поиск по построенному индексу

#### Замечание:
+ в рамках выполнения задания должны быть реализованы:
	* операторы AND, OR, NOT
	* возможность вводить сложный запрос ( например, (Клеопатра  AND Цезарь) OR (Антоний AND Цицерон) OR Помпей
+ реализована возможность водить  запрос  строку запроса (то есть запрос не "хардкодим")

Примеры запросов для моей программы: _прокомментировать & сумма_, _! тарасов_, _прокомментировать | целый_, _сумма & прокомментировать | целый & турция | завоевать_

### Task 4

Для каждого cкаченного документа из Задания 1:
+ Подсчитать tf каждого термина (см. список терминов из Задания 2)
+ Подсчитать idf для термина
+ Подсчитать tf  для каждой лемматизированной формы (см. список форм  из Задания 2)  как  отношение сумм вхождения числа терминов  к общему количеству терминов в документе
+ Подсчитать idf

